{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11661991,"sourceType":"datasetVersion","datasetId":7318726}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8a63b381","cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset, DatasetDict\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nfrom collections import Counter\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, hamming_loss\nfrom sklearn.utils.class_weight import compute_class_weight\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:40:46.135367Z","iopub.execute_input":"2025-05-03T18:40:46.135683Z","iopub.status.idle":"2025-05-03T18:41:20.001707Z","shell.execute_reply.started":"2025-05-03T18:40:46.135642Z","shell.execute_reply":"2025-05-03T18:41:20.000866Z"}},"outputs":[{"name":"stderr","text":"2025-05-03 18:41:03.554028: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746297663.788151      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746297663.856853      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"id":"3934c9a9","cell_type":"code","source":"df = pd.read_csv('/kaggle/input/mephi-hack2/cleared_one_class.csv')\n# df = pd.read_csv('../data/processed/cleared_one_class.csv')\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:20.003170Z","iopub.execute_input":"2025-05-03T18:41:20.003746Z","iopub.status.idle":"2025-05-03T18:41:20.207647Z","shell.execute_reply.started":"2025-05-03T18:41:20.003725Z","shell.execute_reply":"2025-05-03T18:41:20.206989Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4191 entries, 0 to 4190\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    4191 non-null   object\n 1   class   4191 non-null   object\ndtypes: object(2)\nmemory usage: 65.6+ KB\n","output_type":"stream"}],"execution_count":2},{"id":"3627500d","cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:20.208437Z","iopub.execute_input":"2025-05-03T18:41:20.208749Z","iopub.status.idle":"2025-05-03T18:41:20.229809Z","shell.execute_reply.started":"2025-05-03T18:41:20.208728Z","shell.execute_reply":"2025-05-03T18:41:20.229004Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                text         class\n0  ⭐️  кнопка: ⭐️start⭐️(https://t.me/major/start...       соцсети\n1  а продолжение где? правильно. в моем сообществ...       соцсети\n2  тем временем моя авторская телега уверенно в т...       соцсети\n3  у меня есть двоюродная сестра, у нее есть сын ...  личная жизнь\n4  тем временем моя авторская телега уверенно в т...       соцсети","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>⭐️  кнопка: ⭐️start⭐️(https://t.me/major/start...</td>\n      <td>соцсети</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>а продолжение где? правильно. в моем сообществ...</td>\n      <td>соцсети</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>тем временем моя авторская телега уверенно в т...</td>\n      <td>соцсети</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>у меня есть двоюродная сестра, у нее есть сын ...</td>\n      <td>личная жизнь</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>тем временем моя авторская телега уверенно в т...</td>\n      <td>соцсети</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"id":"395d0901","cell_type":"code","source":"# Инициализируем энкодер\nencoder = LabelEncoder()\n\nlabels =encoder.fit_transform(df['class'])\ndf['labels'] = labels\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:20.231421Z","iopub.execute_input":"2025-05-03T18:41:20.231613Z","iopub.status.idle":"2025-05-03T18:41:20.241364Z","shell.execute_reply.started":"2025-05-03T18:41:20.231598Z","shell.execute_reply":"2025-05-03T18:41:20.240691Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text         class  labels\n0  ⭐️  кнопка: ⭐️start⭐️(https://t.me/major/start...       соцсети       3\n1  а продолжение где? правильно. в моем сообществ...       соцсети       3\n2  тем временем моя авторская телега уверенно в т...       соцсети       3\n3  у меня есть двоюродная сестра, у нее есть сын ...  личная жизнь       0\n4  тем временем моя авторская телега уверенно в т...       соцсети       3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>⭐️  кнопка: ⭐️start⭐️(https://t.me/major/start...</td>\n      <td>соцсети</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>а продолжение где? правильно. в моем сообществ...</td>\n      <td>соцсети</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>тем временем моя авторская телега уверенно в т...</td>\n      <td>соцсети</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>у меня есть двоюродная сестра, у нее есть сын ...</td>\n      <td>личная жизнь</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>тем временем моя авторская телега уверенно в т...</td>\n      <td>соцсети</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"0c15da19","cell_type":"code","source":"class_mapping = {label: idx for idx, label in enumerate(encoder.classes_)}\nclass_mapping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:20.242146Z","iopub.execute_input":"2025-05-03T18:41:20.242729Z","iopub.status.idle":"2025-05-03T18:41:20.257682Z","shell.execute_reply.started":"2025-05-03T18:41:20.242703Z","shell.execute_reply":"2025-05-03T18:41:20.257025Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'личная жизнь': 0,\n 'политика': 1,\n 'реклама': 2,\n 'соцсети': 3,\n 'спорт': 4,\n 'юмор': 5}"},"metadata":{}}],"execution_count":5},{"id":"dbeb86cb","cell_type":"code","source":"df=df.drop(columns=['class'])\ntrain_df, val_df = train_test_split(df, stratify=df['labels'], random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:20.258461Z","iopub.execute_input":"2025-05-03T18:41:20.258695Z","iopub.status.idle":"2025-05-03T18:41:20.279123Z","shell.execute_reply.started":"2025-05-03T18:41:20.258676Z","shell.execute_reply":"2025-05-03T18:41:20.278333Z"}},"outputs":[],"execution_count":6},{"id":"a31f49fe","cell_type":"code","source":"# Находим количество примеров в каждом классе\nclass_counts = train_df['labels'].value_counts()\nmax_count = class_counts.max()\n\n# Функция для оверсэмплинга каждого класса\nresampled_dfs = []\nfor class_label in class_counts.index:\n    class_df = train_df[train_df['labels'] == class_label]\n    if len(class_df) < max_count:\n        # Дублируем примеры, пока не достигнем max_count\n        class_df = class_df.sample(max_count, replace=True, random_state=42)\n    resampled_dfs.append(class_df)\n\n# Объединяем обратно\ntrain_df = pd.concat(resampled_dfs, axis=0).sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:20.280095Z","iopub.execute_input":"2025-05-03T18:41:20.280361Z","iopub.status.idle":"2025-05-03T18:41:20.298600Z","shell.execute_reply.started":"2025-05-03T18:41:20.280340Z","shell.execute_reply":"2025-05-03T18:41:20.297868Z"}},"outputs":[],"execution_count":7},{"id":"376ad0c7","cell_type":"code","source":"texts = train_df['text'].to_numpy()\nlabels = train_df['labels'].to_numpy()\nprint(Counter(labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:20.299866Z","iopub.execute_input":"2025-05-03T18:41:20.300578Z","iopub.status.idle":"2025-05-03T18:41:20.307408Z","shell.execute_reply.started":"2025-05-03T18:41:20.300555Z","shell.execute_reply":"2025-05-03T18:41:20.306538Z"}},"outputs":[{"name":"stdout","text":"Counter({1: 979, 0: 979, 4: 979, 3: 979, 2: 979, 5: 979})\n","output_type":"stream"}],"execution_count":8},{"id":"8d8923bd","cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\n\ndataset = DatasetDict({\n    'train' : train_dataset,\n    'val': val_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:20.308137Z","iopub.execute_input":"2025-05-03T18:41:20.308368Z","iopub.status.idle":"2025-05-03T18:41:20.409329Z","shell.execute_reply.started":"2025-05-03T18:41:20.308318Z","shell.execute_reply":"2025-05-03T18:41:20.408737Z"}},"outputs":[],"execution_count":9},{"id":"13e0d7fd","cell_type":"code","source":"# Токенизация\ntokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:20.411778Z","iopub.execute_input":"2025-05-03T18:41:20.412025Z","iopub.status.idle":"2025-05-03T18:41:37.359122Z","shell.execute_reply.started":"2025-05-03T18:41:20.412008Z","shell.execute_reply":"2025-05-03T18:41:37.358320Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8340e3d5abb94cb98ae7a16a7db3cf61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f4f191ec4b34c9d81d7140912bca56d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a927b7bb9e834709a71c8142e6071d57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8928d9abe544b31bd6c082ea931f920"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5874 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"891cf1bd9aac4213a0e201b656682f53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1048 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b68e7ec122408eb7ec5eed1a2b0b24"}},"metadata":{}}],"execution_count":10},{"id":"2ae4ae1d","cell_type":"code","source":"tokenized_datasets.set_format('torch')\ntokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:37.360021Z","iopub.execute_input":"2025-05-03T18:41:37.360269Z","iopub.status.idle":"2025-05-03T18:41:37.365938Z","shell.execute_reply.started":"2025-05-03T18:41:37.360251Z","shell.execute_reply":"2025-05-03T18:41:37.365204Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 5874\n    })\n    val: Dataset({\n        features: ['text', 'labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1048\n    })\n})"},"metadata":{}}],"execution_count":11},{"id":"ad4027bd","cell_type":"code","source":"# 5. Инициализация модели (остается без изменений)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = BertForSequenceClassification.from_pretrained(\n    'DeepPavlov/rubert-base-cased',\n    num_labels=6\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T18:41:37.367104Z","iopub.execute_input":"2025-05-03T18:41:37.367398Z","iopub.status.idle":"2025-05-03T18:41:42.286448Z","shell.execute_reply.started":"2025-05-03T18:41:37.367375Z","shell.execute_reply":"2025-05-03T18:41:42.282062Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"255a9363292c4bd5a170f3c59dda9cb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9f7cbe6271f4f7a90f4605cb619839a"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"id":"53875223","cell_type":"code","source":"# Создание модели\nmodel = BertForSequenceClassification.from_pretrained(\n    \"DeepPavlov/rubert-base-cased\", \n    num_labels=len(class_mapping)\n    )\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)  # Для multi-class\n    \n    # Для multi-label (раскомментировать):\n    # predictions = (predictions > 0).astype(int)  # Логиты уже через sigmoid\n    \n    return {\n        'f1 macro': f1_score(labels, predictions, average='macro'),\n        'f1 micro': f1_score(labels, predictions, average='micro'),\n        'f1 weighted': f1_score(labels, predictions, average='weighted'),\n        'accuracy': accuracy_score(labels, predictions),\n        'precision': precision_score(labels, predictions, average='macro'),\n        'recall': recall_score(labels, predictions, average='macro'),\n        'Loss': hamming_loss(labels, predictions)\n    }\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=8,\n    num_train_epochs=20,\n    eval_strategy=\"steps\",\n    log_level='info',\n    do_train=True,  # Ключевое изменение!\n    do_eval=True,\n    logging_steps=200,\n    save_steps=500,\n    eval_steps=200,\n    fp16=True,  # Если GPU поддерживает\n    report_to=[\"tensorboard\"],\n    metric_for_best_model='eval_f1 micro'\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"val\"],\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:19:12.598353Z","iopub.execute_input":"2025-05-03T19:19:12.599082Z","iopub.status.idle":"2025-05-03T19:19:14.297408Z","shell.execute_reply.started":"2025-05-03T19:19:12.599044Z","shell.execute_reply":"2025-05-03T19:19:14.296863Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased/snapshots/4036cab694767a299f2b9e6492909664d9414229/config.json\nModel config BertConfig {\n  \"architectures\": [\n    \"BertModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\",\n    \"3\": \"LABEL_3\",\n    \"4\": \"LABEL_4\",\n    \"5\": \"LABEL_5\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2,\n    \"LABEL_3\": 3,\n    \"LABEL_4\": 4,\n    \"LABEL_5\": 5\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.51.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 119547\n}\n\nloading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--DeepPavlov--rubert-base-cased/snapshots/4036cab694767a299f2b9e6492909664d9414229/pytorch_model.bin\nAttempting to create safetensors variant\nSafetensors PR exists\nSome weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nPyTorch: setting up devices\nUsing auto half precision backend\n","output_type":"stream"}],"execution_count":15},{"id":"5bb8ae22","cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T19:19:14.298724Z","iopub.execute_input":"2025-05-03T19:19:14.298992Z","iopub.status.idle":"2025-05-03T21:10:19.849444Z","shell.execute_reply.started":"2025-05-03T19:19:14.298973Z","shell.execute_reply":"2025-05-03T21:10:19.848867Z"}},"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 5,874\n  Num Epochs = 20\n  Instantaneous batch size per device = 16\n  Training with DataParallel so batch size has been adjusted to: 32\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 3,680\n  Number of trainable parameters = 177,858,054\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3680' max='3680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3680/3680 1:51:03, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1 macro</th>\n      <th>F1 micro</th>\n      <th>F1 weighted</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>0.840100</td>\n      <td>0.278626</td>\n      <td>0.699041</td>\n      <td>0.721374</td>\n      <td>0.715083</td>\n      <td>0.721374</td>\n      <td>0.709564</td>\n      <td>0.708721</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.261400</td>\n      <td>0.269084</td>\n      <td>0.710895</td>\n      <td>0.730916</td>\n      <td>0.728045</td>\n      <td>0.730916</td>\n      <td>0.727292</td>\n      <td>0.703191</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.144300</td>\n      <td>0.269084</td>\n      <td>0.706626</td>\n      <td>0.730916</td>\n      <td>0.725945</td>\n      <td>0.730916</td>\n      <td>0.722974</td>\n      <td>0.698021</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.159800</td>\n      <td>0.260496</td>\n      <td>0.723936</td>\n      <td>0.739504</td>\n      <td>0.739508</td>\n      <td>0.739504</td>\n      <td>0.727794</td>\n      <td>0.729848</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.141200</td>\n      <td>0.265267</td>\n      <td>0.700980</td>\n      <td>0.734733</td>\n      <td>0.728930</td>\n      <td>0.734733</td>\n      <td>0.699165</td>\n      <td>0.714949</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.116700</td>\n      <td>0.239504</td>\n      <td>0.735320</td>\n      <td>0.760496</td>\n      <td>0.755472</td>\n      <td>0.760496</td>\n      <td>0.746994</td>\n      <td>0.731653</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.081500</td>\n      <td>0.255725</td>\n      <td>0.729284</td>\n      <td>0.744275</td>\n      <td>0.743234</td>\n      <td>0.744275</td>\n      <td>0.728946</td>\n      <td>0.736252</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.080000</td>\n      <td>0.252863</td>\n      <td>0.726695</td>\n      <td>0.747137</td>\n      <td>0.746698</td>\n      <td>0.747137</td>\n      <td>0.740501</td>\n      <td>0.718848</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.097700</td>\n      <td>0.266221</td>\n      <td>0.721849</td>\n      <td>0.733779</td>\n      <td>0.734508</td>\n      <td>0.733779</td>\n      <td>0.727974</td>\n      <td>0.723507</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.076500</td>\n      <td>0.268130</td>\n      <td>0.709653</td>\n      <td>0.731870</td>\n      <td>0.730432</td>\n      <td>0.731870</td>\n      <td>0.708572</td>\n      <td>0.717911</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.061000</td>\n      <td>0.253817</td>\n      <td>0.726008</td>\n      <td>0.746183</td>\n      <td>0.739719</td>\n      <td>0.746183</td>\n      <td>0.738915</td>\n      <td>0.719777</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.062100</td>\n      <td>0.257634</td>\n      <td>0.727430</td>\n      <td>0.742366</td>\n      <td>0.744680</td>\n      <td>0.742366</td>\n      <td>0.743484</td>\n      <td>0.727477</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.053300</td>\n      <td>0.262405</td>\n      <td>0.720039</td>\n      <td>0.737595</td>\n      <td>0.737068</td>\n      <td>0.737595</td>\n      <td>0.733726</td>\n      <td>0.715920</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.037200</td>\n      <td>0.256679</td>\n      <td>0.722191</td>\n      <td>0.743321</td>\n      <td>0.741609</td>\n      <td>0.743321</td>\n      <td>0.736647</td>\n      <td>0.721580</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.037700</td>\n      <td>0.246183</td>\n      <td>0.732154</td>\n      <td>0.753817</td>\n      <td>0.749734</td>\n      <td>0.753817</td>\n      <td>0.746598</td>\n      <td>0.723851</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.036700</td>\n      <td>0.272901</td>\n      <td>0.707783</td>\n      <td>0.727099</td>\n      <td>0.729137</td>\n      <td>0.727099</td>\n      <td>0.716081</td>\n      <td>0.707591</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.028800</td>\n      <td>0.261450</td>\n      <td>0.724603</td>\n      <td>0.738550</td>\n      <td>0.739055</td>\n      <td>0.738550</td>\n      <td>0.732128</td>\n      <td>0.728479</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.042300</td>\n      <td>0.253817</td>\n      <td>0.731861</td>\n      <td>0.746183</td>\n      <td>0.745931</td>\n      <td>0.746183</td>\n      <td>0.734673</td>\n      <td>0.732617</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to /kaggle/working/results/checkpoint-500\nConfiguration saved in /kaggle/working/results/checkpoint-500/config.json\nModel weights saved in /kaggle/working/results/checkpoint-500/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\nSaving model checkpoint to /kaggle/working/results/checkpoint-1000\nConfiguration saved in /kaggle/working/results/checkpoint-1000/config.json\nModel weights saved in /kaggle/working/results/checkpoint-1000/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to /kaggle/working/results/checkpoint-1500\nConfiguration saved in /kaggle/working/results/checkpoint-1500/config.json\nModel weights saved in /kaggle/working/results/checkpoint-1500/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\nSaving model checkpoint to /kaggle/working/results/checkpoint-2000\nConfiguration saved in /kaggle/working/results/checkpoint-2000/config.json\nModel weights saved in /kaggle/working/results/checkpoint-2000/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to /kaggle/working/results/checkpoint-2500\nConfiguration saved in /kaggle/working/results/checkpoint-2500/config.json\nModel weights saved in /kaggle/working/results/checkpoint-2500/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\nSaving model checkpoint to /kaggle/working/results/checkpoint-3000\nConfiguration saved in /kaggle/working/results/checkpoint-3000/config.json\nModel weights saved in /kaggle/working/results/checkpoint-3000/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to /kaggle/working/results/checkpoint-3500\nConfiguration saved in /kaggle/working/results/checkpoint-3500/config.json\nModel weights saved in /kaggle/working/results/checkpoint-3500/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to /kaggle/working/results/checkpoint-3680\nConfiguration saved in /kaggle/working/results/checkpoint-3680/config.json\nModel weights saved in /kaggle/working/results/checkpoint-3680/model.safetensors\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3680, training_loss=0.12869091665615207, metrics={'train_runtime': 6664.8279, 'train_samples_per_second': 17.627, 'train_steps_per_second': 0.552, 'total_flos': 3.091139690766336e+16, 'train_loss': 0.12869091665615207, 'epoch': 20.0})"},"metadata":{}}],"execution_count":16},{"id":"fa23707b","cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/my_bert_one_aug_classifier\")\ntokenizer.save_pretrained(\"/kaggle/working/my_bert_one_aug_classifier\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T21:10:19.850197Z","iopub.execute_input":"2025-05-03T21:10:19.850373Z","iopub.status.idle":"2025-05-03T21:10:21.628552Z","shell.execute_reply.started":"2025-05-03T21:10:19.850358Z","shell.execute_reply":"2025-05-03T21:10:21.627693Z"}},"outputs":[{"name":"stderr","text":"Configuration saved in /kaggle/working/my_bert_one_aug_classifier/config.json\nModel weights saved in /kaggle/working/my_bert_one_aug_classifier/model.safetensors\ntokenizer config file saved in /kaggle/working/my_bert_one_aug_classifier/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/my_bert_one_aug_classifier/special_tokens_map.json\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/my_bert_one_aug_classifier/tokenizer_config.json',\n '/kaggle/working/my_bert_one_aug_classifier/special_tokens_map.json',\n '/kaggle/working/my_bert_one_aug_classifier/vocab.txt',\n '/kaggle/working/my_bert_one_aug_classifier/added_tokens.json')"},"metadata":{}}],"execution_count":17},{"id":"5f60dc95","cell_type":"code","source":"print(trainer.evaluate()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T21:10:21.629468Z","iopub.execute_input":"2025-05-03T21:10:21.629773Z","iopub.status.idle":"2025-05-03T21:10:41.444903Z","shell.execute_reply.started":"2025-05-03T21:10:21.629746Z","shell.execute_reply":"2025-05-03T21:10:41.444009Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 1048\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [66/66 00:19]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 4.122381687164307, 'eval_f1 macro': 0.7308203053209227, 'eval_f1 micro': 0.7452290076335878, 'eval_f1 weighted': 0.7449970772321786, 'eval_accuracy': 0.7452290076335878, 'eval_precision': 0.7336519775713232, 'eval_recall': 0.7317164762423718, 'eval_Loss': 0.2547709923664122, 'eval_runtime': 19.8025, 'eval_samples_per_second': 52.923, 'eval_steps_per_second': 3.333, 'epoch': 20.0}\n","output_type":"stream"}],"execution_count":18},{"id":"58bff270","cell_type":"code","source":"new_texts = [\"Анкара Месси забил гол в ворота франции\", \"ай Литвин красава ай чисто на кондциях залетел ай да лев\", \"Америка расширила список санкция против России\", \"купите макбук за 140к и получите наушники в подарок\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T21:10:41.447184Z","iopub.execute_input":"2025-05-03T21:10:41.447414Z","iopub.status.idle":"2025-05-03T21:10:41.451637Z","shell.execute_reply.started":"2025-05-03T21:10:41.447396Z","shell.execute_reply":"2025-05-03T21:10:41.450758Z"}},"outputs":[],"execution_count":19},{"id":"3aa8b3e2","cell_type":"code","source":"def predict(text):\n    # Токенизация текста\n    inputs = tokenizer(\n        text,\n        padding=True,\n        truncation=True,\n        max_length=512,\n        return_tensors=\"pt\"\n    ).to(device)\n    \n    # Предсказание\n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    # Получение метки класса\n    probs = torch.softmax(outputs.logits, dim=1)\n    pred_class = torch.argmax(probs).item()\n    \n    id2label = {\n        0: \"личная жизнь\",\n        1: \"политика\", \n        2: \"реклама\",\n        3: \"соцсети\",\n        4: \"спорт\",\n        5: \"юмор\"\n    }\n\n    for class_id, prob in enumerate(probs.cpu().numpy()[0]):\n        print(f\"{id2label[class_id]}: {prob:.4f}\")  # 4 знака после запятой","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T21:10:41.452645Z","iopub.execute_input":"2025-05-03T21:10:41.452918Z","iopub.status.idle":"2025-05-03T21:10:41.472007Z","shell.execute_reply.started":"2025-05-03T21:10:41.452898Z","shell.execute_reply":"2025-05-03T21:10:41.471184Z"}},"outputs":[],"execution_count":20},{"id":"e1d0df85","cell_type":"code","source":"class_mapping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T21:10:41.472787Z","iopub.execute_input":"2025-05-03T21:10:41.473152Z","iopub.status.idle":"2025-05-03T21:10:41.488664Z","shell.execute_reply.started":"2025-05-03T21:10:41.473128Z","shell.execute_reply":"2025-05-03T21:10:41.488087Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'личная жизнь': 0,\n 'политика': 1,\n 'реклама': 2,\n 'соцсети': 3,\n 'спорт': 4,\n 'юмор': 5}"},"metadata":{}}],"execution_count":21},{"id":"778e9d12","cell_type":"code","source":"predict('Спортивная энергия в каждом глотке — заряжайся и побеждай с новым напитком для чемпионов!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T21:10:41.489555Z","iopub.execute_input":"2025-05-03T21:10:41.489853Z","iopub.status.idle":"2025-05-03T21:10:41.589541Z","shell.execute_reply.started":"2025-05-03T21:10:41.489810Z","shell.execute_reply":"2025-05-03T21:10:41.588699Z"}},"outputs":[{"name":"stdout","text":"личная жизнь: 0.0000\nполитика: 0.0000\nреклама: 0.0000\nсоцсети: 0.0000\nспорт: 1.0000\nюмор: 0.0000\n","output_type":"stream"}],"execution_count":22},{"id":"4d785251","cell_type":"code","source":"predict('Достигай рекордов с кроссовками, которые выбирают профи!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T21:10:41.590397Z","iopub.execute_input":"2025-05-03T21:10:41.590663Z","iopub.status.idle":"2025-05-03T21:10:41.608056Z","shell.execute_reply.started":"2025-05-03T21:10:41.590644Z","shell.execute_reply":"2025-05-03T21:10:41.607245Z"}},"outputs":[{"name":"stdout","text":"личная жизнь: 0.0000\nполитика: 0.0000\nреклама: 0.0000\nсоцсети: 0.0000\nспорт: 0.0000\nюмор: 1.0000\n","output_type":"stream"}],"execution_count":23},{"id":"87928a00","cell_type":"code","source":"predict('Подпитывай чемпионский дух — белковый батончик для твоих тренировок!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T22:04:48.480728Z","iopub.execute_input":"2025-05-03T22:04:48.480997Z","iopub.status.idle":"2025-05-03T22:04:48.501056Z","shell.execute_reply.started":"2025-05-03T22:04:48.480978Z","shell.execute_reply":"2025-05-03T22:04:48.500074Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3634404017.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Подпитывай чемпионский дух — белковый батончик для твоих тренировок!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"],"ename":"NameError","evalue":"name 'predict' is not defined","output_type":"error"}],"execution_count":1}]}