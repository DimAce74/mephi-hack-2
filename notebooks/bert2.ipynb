{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2aed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification\n",
      "  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.2.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2.4.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\n",
      "Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a63b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:01:00.578563: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746468060.750752      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746468060.801616      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import ast\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from tqdm.auto import tqdm  # Для прогресс-бара\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3934c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11346 entries, 0 to 11345\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  11346 non-null  int64 \n",
      " 1   text        11346 non-null  object\n",
      " 2   class       11346 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 266.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/multi-l/cleared_new.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3627500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].apply(lambda x: ast.literal_eval(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395d0901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>твой лучший секс спрятан делюсь каналом диплом...</td>\n",
       "      <td>[реклама, личная жизнь]</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>кнопка start</td>\n",
       "      <td>[соцсети]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>продолжение правильно моем сообществе вк ссылк...</td>\n",
       "      <td>[соцсети]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>временем авторская телега уверенно тройке силь...</td>\n",
       "      <td>[соцсети]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>двоюродная сестра сын антон двоюродный племянн...</td>\n",
       "      <td>[личная жизнь]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  твой лучший секс спрятан делюсь каналом диплом...   \n",
       "1           1                                       кнопка start   \n",
       "2           2  продолжение правильно моем сообществе вк ссылк...   \n",
       "3           3  временем авторская телега уверенно тройке силь...   \n",
       "4           4  двоюродная сестра сын антон двоюродный племянн...   \n",
       "\n",
       "                     class              labels  \n",
       "0  [реклама, личная жизнь]  [1, 0, 1, 0, 0, 0]  \n",
       "1                [соцсети]  [0, 0, 0, 1, 0, 0]  \n",
       "2                [соцсети]  [0, 0, 0, 1, 0, 0]  \n",
       "3                [соцсети]  [0, 0, 0, 1, 0, 0]  \n",
       "4           [личная жизнь]  [1, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = ['личная жизнь', 'политика', 'реклама', 'соцсети', 'спорт', 'юмор']\n",
    "\n",
    "# Сортируем метки для воспроизводимости\n",
    "sorted_labels = sorted(all_labels)\n",
    "\n",
    "# Инициализируем бинаризатор\n",
    "mlb = MultiLabelBinarizer(classes=sorted_labels)\n",
    "mlb.fit(sorted_labels)\n",
    "\n",
    "binary_matrix = mlb.transform(df['class'])\n",
    "df['labels'] = list(binary_matrix)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c15da19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'личная жизнь': 0,\n",
       " 'политика': 1,\n",
       " 'реклама': 2,\n",
       " 'соцсети': 3,\n",
       " 'спорт': 4,\n",
       " 'юмор': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping = {label: idx for idx, label in enumerate(mlb.classes_)}\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8923bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dataset = Dataset.from_pandas(df)\n",
    "# Бинарные метки (n_samples, n_classes)\n",
    "labels = np.array(pre_dataset[\"labels\"])\n",
    "\n",
    "# Стратифицированное разбиение\n",
    "msss = MultilabelStratifiedShuffleSplit(\n",
    "    n_splits=1,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_idx, val_idx = next(msss.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "train_dataset = pre_dataset.select(train_idx)\n",
    "val_dataset = pre_dataset.select(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6023dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train распределение:\n",
      "0     851\n",
      "1     622\n",
      "2    1678\n",
      "3    1144\n",
      "4    2752\n",
      "5    1745\n",
      "dtype: int64\n",
      "Validation распределение:\n",
      "0    213\n",
      "1    156\n",
      "2    420\n",
      "3    286\n",
      "4    688\n",
      "5    437\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def print_label_distribution(pre_dataset, name):\n",
    "    labels = np.array(pre_dataset[\"labels\"])\n",
    "    label_counts = pd.DataFrame(labels).sum(axis=0)\n",
    "    print(f\"{name} распределение:\\n{label_counts}\")\n",
    "\n",
    "print_label_distribution(train_dataset, \"Train\")\n",
    "print_label_distribution(val_dataset, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c9d2d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9076, 4)\n",
      "(2270, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train = train_dataset.to_pandas()\n",
    "df_val = val_dataset.to_pandas()\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8277271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a108b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae4ae1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac15568fcbb443fb6c9469eb87c49df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66737c260db1415f9776714e5b3fde3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c193e3d898104d10a9bec9f4f9e6f20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3904553ca5643228bc5e014f4677802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/909355386.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  torch.tensor(df_train['labels'], dtype=torch.float32)  # float32 для multi-label\n"
     ]
    }
   ],
   "source": [
    "# Токенизация\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "inputs = tokenizer(df_train['text'].to_list(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Создаем TensorDataset\n",
    "dataset = TensorDataset(\n",
    "    inputs['input_ids'],\n",
    "    inputs['attention_mask'],\n",
    "    torch.tensor(df_train['labels'], dtype=torch.float32)  # float32 для multi-label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fa0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DataLoader\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    sampler=RandomSampler(dataset),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad4027bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7d2750b44b4d40859d3a6e556c4708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 5. Инициализация модели (остается без изменений)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-multilingual-cased',\n",
    "    num_labels=6,  # Автоматическое определение числа классов\n",
    "    problem_type=\"multi_label_classification\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53875223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8823f87b17f84ac5a5a77bbd9aaadecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Train]:   0%|          | 0/568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3978744039.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Сбор статистики\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Функция вычисления accuracy\n",
    "def compute_accuracy(preds, labels):\n",
    "    if len(labels.shape) > 1:  # Для multi-label\n",
    "        preds = (torch.sigmoid(preds) > 0.5).int()\n",
    "    else:  # Для multi-class\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "    return accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
    "\n",
    "# Цикл обучения\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    # Прогресс-бар для обучения\n",
    "    train_progress = tqdm(dataloader, desc=f'Epoch {epoch + 1}/{epochs} [Train]', leave=False)\n",
    "    \n",
    "    for batch in train_progress:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Сбор статистики\n",
    "        total_loss += loss.item()\n",
    "        all_preds.append(outputs.logits.detach())\n",
    "        all_labels.append(labels)\n",
    "        \n",
    "        # Обновление прогресс-бара\n",
    "        train_progress.set_postfix({\n",
    "            'loss': loss.item(),\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "    \n",
    "    # Вычисление accuracy\n",
    "    epoch_preds = torch.cat(all_preds)\n",
    "    epoch_labels = torch.cat(all_labels)\n",
    "    acc = compute_accuracy(epoch_preds, epoch_labels)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1} | Loss: {total_loss/len(dataloader):.4f} | Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc644fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/kaggle/working//my_bert_classifier\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working//my_bert_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9bcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    # Для multi-class классификации\n",
    "    if len(labels.shape) == 1:\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    # Для multi-label классификации\n",
    "    else:\n",
    "        preds = (preds > 0.5).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'f1': f1_score(labels, preds, average='macro'),\n",
    "        'precision': precision_score(labels, preds, average='macro'),\n",
    "        'recall': recall_score(labels, preds, average='macro'),\n",
    "        'accuracy': accuracy_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039db654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация\n",
    "inputs_val = tokenizer(df_val['text'].to_list(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Создаем TensorDataset\n",
    "dataset_val = TensorDataset(\n",
    "    inputs_val['input_ids'],\n",
    "    inputs_val['attention_mask'],\n",
    "    torch.tensor(df_val['labels'], dtype=torch.float32)  # float32 для multi-label\n",
    ")\n",
    "\n",
    "# 4. DataLoader\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "model.eval()  # Переводим модель в режим оценки\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Для multi-class\n",
    "        # preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        # Для multi-label (раскомментировать):\n",
    "        preds = (torch.sigmoid(logits) > 0.5).int()\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Расчет F1\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, hamming_loss\n",
    "\n",
    "# Расчет F1\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f\"F1-score macro: {f1:.4f}\")\n",
    "f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "print(f\"F1-score micro: {f1:.4f}\")\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "print(f\"F1-score weighted: {f1:.4f}\")\n",
    "hamming = hamming_loss(all_labels, all_preds)\n",
    "print(\"Hamming Loss:\", hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58232542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(\n",
    "    all_labels,\n",
    "    all_preds,\n",
    "    target_names=sorted_labels  # Замените на свои названия классов\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/kaggle/working//my_bert_classifier1\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working//my_bert_classifier1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
