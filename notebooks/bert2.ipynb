{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2aed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification\n",
      "  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.2.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->iterative-stratification) (2.4.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->iterative-stratification) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\n",
      "Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a63b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import ast\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from tqdm.auto import tqdm  # –î–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3934c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5700 entries, 0 to 5699\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5700 non-null   object\n",
      " 1   class   5700 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 89.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/cleared-new/cleared_new.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3627500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].apply(lambda x: ast.literal_eval(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395d0901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>—Ç–≤–æ–π –ª—É—á—à–∏–π —Å–µ–∫—Å —Å–ø—Ä—è—Ç–∞–Ω –∑–¥–µ—Å—å üîû  –¥–µ–ª—é—Å—å –∫–∞–Ω–∞–ª...</td>\n",
       "      <td>[—Ä–µ–∫–ª–∞–º–∞, –ª–∏—á–Ω–∞—è –∂–∏–∑–Ω—å]</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚≠êÔ∏è  –∫–Ω–æ–ø–∫–∞: ‚≠êÔ∏èstart‚≠êÔ∏è(https://t.me/major/start...</td>\n",
       "      <td>[—Å–æ—Ü—Å–µ—Ç–∏]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≥–¥–µ? –ø—Ä–∞–≤–∏–ª—å–Ω–æ. –≤ –º–æ–µ–º —Å–æ–æ–±—â–µ—Å—Ç–≤...</td>\n",
       "      <td>[—Å–æ—Ü—Å–µ—Ç–∏]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>—Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –º–æ—è –∞–≤—Ç–æ—Ä—Å–∫–∞—è —Ç–µ–ª–µ–≥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ –≤ —Ç...</td>\n",
       "      <td>[—Å–æ—Ü—Å–µ—Ç–∏]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>—É –º–µ–Ω—è –µ—Å—Ç—å –¥–≤–æ—é—Ä–æ–¥–Ω–∞—è —Å–µ—Å—Ç—Ä–∞, —É –Ω–µ–µ –µ—Å—Ç—å —Å—ã–Ω ...</td>\n",
       "      <td>[–ª–∏—á–Ω–∞—è –∂–∏–∑–Ω—å]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                    class  \\\n",
       "0  —Ç–≤–æ–π –ª—É—á—à–∏–π —Å–µ–∫—Å —Å–ø—Ä—è—Ç–∞–Ω –∑–¥–µ—Å—å üîû  –¥–µ–ª—é—Å—å –∫–∞–Ω–∞–ª...  [—Ä–µ–∫–ª–∞–º–∞, –ª–∏—á–Ω–∞—è –∂–∏–∑–Ω—å]   \n",
       "1  ‚≠êÔ∏è  –∫–Ω–æ–ø–∫–∞: ‚≠êÔ∏èstart‚≠êÔ∏è(https://t.me/major/start...                [—Å–æ—Ü—Å–µ—Ç–∏]   \n",
       "2  –∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≥–¥–µ? –ø—Ä–∞–≤–∏–ª—å–Ω–æ. –≤ –º–æ–µ–º —Å–æ–æ–±—â–µ—Å—Ç–≤...                [—Å–æ—Ü—Å–µ—Ç–∏]   \n",
       "3  —Ç–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –º–æ—è –∞–≤—Ç–æ—Ä—Å–∫–∞—è —Ç–µ–ª–µ–≥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ –≤ —Ç...                [—Å–æ—Ü—Å–µ—Ç–∏]   \n",
       "4  —É –º–µ–Ω—è –µ—Å—Ç—å –¥–≤–æ—é—Ä–æ–¥–Ω–∞—è —Å–µ—Å—Ç—Ä–∞, —É –Ω–µ–µ –µ—Å—Ç—å —Å—ã–Ω ...           [–ª–∏—á–Ω–∞—è –∂–∏–∑–Ω—å]   \n",
       "\n",
       "               labels  \n",
       "0  [1, 0, 1, 0, 0, 0]  \n",
       "1  [0, 0, 0, 1, 0, 0]  \n",
       "2  [0, 0, 0, 1, 0, 0]  \n",
       "3  [0, 0, 0, 1, 0, 0]  \n",
       "4  [1, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = ['–ª–∏—á–Ω–∞—è –∂–∏–∑–Ω—å', '–ø–æ–ª–∏—Ç–∏–∫–∞', '—Ä–µ–∫–ª–∞–º–∞', '—Å–æ—Ü—Å–µ—Ç–∏', '—Å–ø–æ—Ä—Ç', '—é–º–æ—Ä']\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç–∫–∏ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "sorted_labels = sorted(all_labels)\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∏–Ω–∞—Ä–∏–∑–∞—Ç–æ—Ä\n",
    "mlb = MultiLabelBinarizer(classes=sorted_labels)\n",
    "mlb.fit(sorted_labels)\n",
    "\n",
    "binary_matrix = mlb.transform(df['class'])\n",
    "df['labels'] = list(binary_matrix)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c15da19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'–ª–∏—á–Ω–∞—è –∂–∏–∑–Ω—å': 0,\n",
       " '–ø–æ–ª–∏—Ç–∏–∫–∞': 1,\n",
       " '—Ä–µ–∫–ª–∞–º–∞': 2,\n",
       " '—Å–æ—Ü—Å–µ—Ç–∏': 3,\n",
       " '—Å–ø–æ—Ä—Ç': 4,\n",
       " '—é–º–æ—Ä': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping = {label: idx for idx, label in enumerate(mlb.classes_)}\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8923bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dataset = Dataset.from_pandas(df)\n",
    "# –ë–∏–Ω–∞—Ä–Ω—ã–µ –º–µ—Ç–∫–∏ (n_samples, n_classes)\n",
    "labels = np.array(pre_dataset[\"labels\"])\n",
    "\n",
    "# –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ\n",
    "msss = MultilabelStratifiedShuffleSplit(\n",
    "    n_splits=1,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_idx, val_idx = next(msss.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "train_dataset = pre_dataset.select(train_idx)\n",
    "val_dataset = pre_dataset.select(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6023dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:\n",
      "0     426\n",
      "1     311\n",
      "2     840\n",
      "3     759\n",
      "4    1376\n",
      "5     873\n",
      "dtype: int64\n",
      "Validation —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:\n",
      "0    107\n",
      "1     78\n",
      "2    210\n",
      "3    190\n",
      "4    344\n",
      "5    218\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def print_label_distribution(pre_dataset, name):\n",
    "    labels = np.array(pre_dataset[\"labels\"])\n",
    "    label_counts = pd.DataFrame(labels).sum(axis=0)\n",
    "    print(f\"{name} —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:\\n{label_counts}\")\n",
    "\n",
    "print_label_distribution(train_dataset, \"Train\")\n",
    "print_label_distribution(val_dataset, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c9d2d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4560, 3)\n",
      "(1140, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = train_dataset.to_pandas()\n",
    "df_val = val_dataset.to_pandas()\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8277271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a108b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae4ae1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc82bbd67704925be7180779bc1b181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441db105f1db4e11826c7f0fabb5d4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952cac2974254616a6cd9787b1102d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718c7b91ba0a4b67abe8e0f47f6e2f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "inputs = tokenizer(df_train['text'].to_list(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º TensorDataset\n",
    "dataset = TensorDataset(\n",
    "    inputs['input_ids'],\n",
    "    inputs['attention_mask'],\n",
    "    torch.tensor(df_train['labels'], dtype=torch.float32)  # float32 –¥–ª—è multi-label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8fa0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DataLoader\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    sampler=RandomSampler(dataset),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad4027bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35781ecaab4f4a6db74da67319544a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 5. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (–æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-multilingual-cased',\n",
    "    num_labels=6,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "    problem_type=\"multi_label_classification\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53875223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc623c79b9a147ba953d97e3e5275837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 | Loss: 0.3460 | Accuracy: 0.3342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85496d8897c43af8706d435ef1986fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 | Loss: 0.3041 | Accuracy: 0.4669\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e37ec24e5e8453b9c4613426c26628e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 | Loss: 0.2720 | Accuracy: 0.5311\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4ee6698bb54fd3b50c77258c4201d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 | Loss: 0.2415 | Accuracy: 0.5846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c54e69be72e4df4b4c87e364d793c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 | Loss: 0.2039 | Accuracy: 0.6658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2938f19251491e99557973a7f9d624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 | Loss: 0.1748 | Accuracy: 0.7092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27374b217a54c4baa9750a2292bb3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 | Loss: 0.1516 | Accuracy: 0.7550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb800c97e58549ef9a5122a23ca4d088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 | Loss: 0.1286 | Accuracy: 0.7822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bc4284105547f281f1955ff163b64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 | Loss: 0.1129 | Accuracy: 0.8127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce236585fbdd42e584220322f4f3b8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 | Loss: 0.0981 | Accuracy: 0.8357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6a100389a44c94bcc5bbee843a3f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 | Loss: 0.0839 | Accuracy: 0.8662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820e04c7a17e4c6d9786ba70b128c749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 | Loss: 0.0793 | Accuracy: 0.8713\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55505d4a4afc4251acc78edae75d5be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 | Loss: 0.0714 | Accuracy: 0.8789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48672d022fad4a41a9bceb40572d2229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 | Loss: 0.0682 | Accuracy: 0.8855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9788b0848247b08f7a90b93eddc32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 | Loss: 0.0589 | Accuracy: 0.9004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439bf57743d74592be2ef33c9c0de63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 | Loss: 0.0571 | Accuracy: 0.9075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a589f4cf1d4565af336ee6642bf3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 | Loss: 0.0527 | Accuracy: 0.9112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca472f006414dad9ea75e20053dde83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 | Loss: 0.0566 | Accuracy: 0.9053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2221c312b20041c087403357430bd681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 | Loss: 0.0526 | Accuracy: 0.9134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7283dd7faae04cf3a32781f0d73829fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20 [Train]:   0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 | Loss: 0.0491 | Accuracy: 0.9195\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è accuracy\n",
    "def compute_accuracy(preds, labels):\n",
    "    if len(labels.shape) > 1:  # –î–ª—è multi-label\n",
    "        preds = (torch.sigmoid(preds) > 0.5).int()\n",
    "    else:  # –î–ª—è multi-class\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "    return accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
    "\n",
    "# –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "    train_progress = tqdm(dataloader, desc=f'Epoch {epoch + 1}/{epochs} [Train]', leave=False)\n",
    "    \n",
    "    for batch in train_progress:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "        total_loss += loss.item()\n",
    "        all_preds.append(outputs.logits.detach())\n",
    "        all_labels.append(labels)\n",
    "        \n",
    "        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞\n",
    "        train_progress.set_postfix({\n",
    "            'loss': loss.item(),\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "    \n",
    "    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ accuracy\n",
    "    epoch_preds = torch.cat(all_preds)\n",
    "    epoch_labels = torch.cat(all_labels)\n",
    "    acc = compute_accuracy(epoch_preds, epoch_labels)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1} | Loss: {total_loss/len(dataloader):.4f} | Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcc644fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working//my_bert_classifier/tokenizer_config.json',\n",
       " '/kaggle/working//my_bert_classifier/special_tokens_map.json',\n",
       " '/kaggle/working//my_bert_classifier/vocab.txt',\n",
       " '/kaggle/working//my_bert_classifier/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"/kaggle/working//my_bert_classifier\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working//my_bert_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a9bcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    # –î–ª—è multi-class –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "    if len(labels.shape) == 1:\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    # –î–ª—è multi-label –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "    else:\n",
    "        preds = (preds > 0.5).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'f1': f1_score(labels, preds, average='macro'),\n",
    "        'precision': precision_score(labels, preds, average='macro'),\n",
    "        'recall': recall_score(labels, preds, average='macro'),\n",
    "        'accuracy': accuracy_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "039db654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "inputs_val = tokenizer(df_val['text'].to_list(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º TensorDataset\n",
    "dataset_val = TensorDataset(\n",
    "    inputs_val['input_ids'],\n",
    "    inputs_val['attention_mask'],\n",
    "    torch.tensor(df_val['labels'], dtype=torch.float32)  # float32 –¥–ª—è multi-label\n",
    ")\n",
    "\n",
    "# 4. DataLoader\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f561c111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.6278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "model.eval()  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # –î–ª—è multi-class\n",
    "        # preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        # –î–ª—è multi-label (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å):\n",
    "        preds = (torch.sigmoid(logits) > 0.5).int()\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç F1\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "748e0708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score macro: 0.6278\n",
      "F1-score micro: 0.6683\n",
      "F1-score weighted: 0.6660\n",
      "Hamming Loss: 0.11915204678362573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, hamming_loss\n",
    "\n",
    "# –†–∞—Å—á–µ—Ç F1\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f\"F1-score macro: {f1:.4f}\")\n",
    "f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "print(f\"F1-score micro: {f1:.4f}\")\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "print(f\"F1-score weighted: {f1:.4f}\")\n",
    "hamming = hamming_loss(all_labels, all_preds)\n",
    "print(\"Hamming Loss:\", hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58232542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "–ª–∏—á–Ω–∞—è –∂–∏–∑–Ω—å       0.42      0.48      0.45       107\n",
      "    –ø–æ–ª–∏—Ç–∏–∫–∞       0.59      0.78      0.67        78\n",
      "     —Ä–µ–∫–ª–∞–º–∞       0.58      0.73      0.65       210\n",
      "     —Å–æ—Ü—Å–µ—Ç–∏       0.51      0.65      0.58       190\n",
      "       —Å–ø–æ—Ä—Ç       0.79      0.92      0.85       344\n",
      "        —é–º–æ—Ä       0.65      0.52      0.58       218\n",
      "\n",
      "   micro avg       0.63      0.72      0.67      1147\n",
      "   macro avg       0.59      0.68      0.63      1147\n",
      "weighted avg       0.63      0.72      0.67      1147\n",
      " samples avg       0.60      0.65      0.61      1147\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(\n",
    "    all_labels,\n",
    "    all_preds,\n",
    "    target_names=sorted_labels  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431f217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /kaggle/working//my_bert_classifier/config.json\n",
      "Model weights saved in /kaggle/working//my_bert_classifier/model.safetensors\n",
      "tokenizer config file saved in /kaggle/working//my_bert_classifier/tokenizer_config.json\n",
      "Special tokens file saved in /kaggle/working//my_bert_classifier/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/kaggle/working//my_bert_classifier/tokenizer_config.json',\n",
       " '/kaggle/working//my_bert_classifier/special_tokens_map.json',\n",
       " '/kaggle/working//my_bert_classifier/vocab.txt',\n",
       " '/kaggle/working//my_bert_classifier/added_tokens.json')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"/kaggle/working//my_bert_classifier1\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working//my_bert_classifier1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
