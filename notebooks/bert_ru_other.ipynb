{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11690461,"sourceType":"datasetVersion","datasetId":7337544},{"sourceId":11691228,"sourceType":"datasetVersion","datasetId":7338038}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8a63b381","cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset, DatasetDict\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nfrom collections import Counter\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, hamming_loss\nfrom sklearn.utils.class_weight import compute_class_weight\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:11:59.973627Z","iopub.execute_input":"2025-05-05T21:11:59.974448Z","iopub.status.idle":"2025-05-05T21:12:31.011419Z","shell.execute_reply.started":"2025-05-05T21:11:59.974416Z","shell.execute_reply":"2025-05-05T21:12:31.010786Z"}},"outputs":[{"name":"stderr","text":"2025-05-05 21:12:15.192154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746479535.424998      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746479535.494212      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"id":"3934c9a9","cell_type":"code","source":"df = pd.read_csv('/kaggle/input/clear-other/cleared_one_other.csv')\n# df = pd.read_csv('../data/processed/cleared_one_class.csv')\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:31.012729Z","iopub.execute_input":"2025-05-05T21:12:31.013310Z","iopub.status.idle":"2025-05-05T21:12:31.271160Z","shell.execute_reply.started":"2025-05-05T21:12:31.013288Z","shell.execute_reply":"2025-05-05T21:12:31.270359Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9881 entries, 0 to 9880\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  9881 non-null   int64 \n 1   text        9881 non-null   object\n 2   class       9881 non-null   object\ndtypes: int64(1), object(2)\nmemory usage: 231.7+ KB\n","output_type":"stream"}],"execution_count":3},{"id":"3627500d","cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:31.271861Z","iopub.execute_input":"2025-05-05T21:12:31.272054Z","iopub.status.idle":"2025-05-05T21:12:31.292772Z","shell.execute_reply.started":"2025-05-05T21:12:31.272038Z","shell.execute_reply":"2025-05-05T21:12:31.291951Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                               text         class\n0           1                                       кнопка start       соцсети\n1           2  продолжение правильно моем сообществе вк ссылк...       соцсети\n2           3  временем авторская телега уверенно тройке силь...       соцсети\n3           4  двоюродная сестра сын антон двоюродный племянн...  личная жизнь\n4           5  временем авторская телега уверенно тройке силь...       соцсети","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>кнопка start</td>\n      <td>соцсети</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>продолжение правильно моем сообществе вк ссылк...</td>\n      <td>соцсети</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>временем авторская телега уверенно тройке силь...</td>\n      <td>соцсети</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>двоюродная сестра сын антон двоюродный племянн...</td>\n      <td>личная жизнь</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>временем авторская телега уверенно тройке силь...</td>\n      <td>соцсети</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"395d0901","cell_type":"code","source":"# Инициализируем энкодер\nencoder = LabelEncoder()\n\nlabels =encoder.fit_transform(df['class'])\ndf['labels'] = labels\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:31.294495Z","iopub.execute_input":"2025-05-05T21:12:31.295012Z","iopub.status.idle":"2025-05-05T21:12:31.305854Z","shell.execute_reply.started":"2025-05-05T21:12:31.294990Z","shell.execute_reply":"2025-05-05T21:12:31.305120Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                               text  \\\n0           1                                       кнопка start   \n1           2  продолжение правильно моем сообществе вк ссылк...   \n2           3  временем авторская телега уверенно тройке силь...   \n3           4  двоюродная сестра сын антон двоюродный племянн...   \n4           5  временем авторская телега уверенно тройке силь...   \n\n          class  labels  \n0       соцсети       4  \n1       соцсети       4  \n2       соцсети       4  \n3  личная жизнь       1  \n4       соцсети       4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>class</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>кнопка start</td>\n      <td>соцсети</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>продолжение правильно моем сообществе вк ссылк...</td>\n      <td>соцсети</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>временем авторская телега уверенно тройке силь...</td>\n      <td>соцсети</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>двоюродная сестра сын антон двоюродный племянн...</td>\n      <td>личная жизнь</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>временем авторская телега уверенно тройке силь...</td>\n      <td>соцсети</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"id":"0c15da19","cell_type":"code","source":"class_mapping = {label: idx for idx, label in enumerate(encoder.classes_)}\nclass_mapping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:31.306640Z","iopub.execute_input":"2025-05-05T21:12:31.306814Z","iopub.status.idle":"2025-05-05T21:12:31.319148Z","shell.execute_reply.started":"2025-05-05T21:12:31.306800Z","shell.execute_reply":"2025-05-05T21:12:31.318549Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'другое': 0,\n 'личная жизнь': 1,\n 'политика': 2,\n 'реклама': 3,\n 'соцсети': 4,\n 'спорт': 5,\n 'юмор': 6}"},"metadata":{}}],"execution_count":6},{"id":"dbeb86cb","cell_type":"code","source":"df=df.drop(columns=['class'])\ntrain_df, val_df = train_test_split(df, stratify=df['labels'], random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:31.319932Z","iopub.execute_input":"2025-05-05T21:12:31.320167Z","iopub.status.idle":"2025-05-05T21:12:31.342135Z","shell.execute_reply.started":"2025-05-05T21:12:31.320150Z","shell.execute_reply":"2025-05-05T21:12:31.341391Z"}},"outputs":[],"execution_count":7},{"id":"a31f49fe","cell_type":"code","source":"# Находим количество примеров в каждом классе\nclass_counts = train_df['labels'].value_counts()\nmax_count = class_counts.max()\n\n# Функция для оверсэмплинга каждого класса\nresampled_dfs = []\nfor class_label in class_counts.index:\n    class_df = train_df[train_df['labels'] == class_label]\n    if len(class_df) < max_count:\n        # Дублируем примеры, пока не достигнем max_count\n        class_df = class_df.sample(max_count, replace=True, random_state=42)\n    resampled_dfs.append(class_df)\n\n# Объединяем обратно\ntrain_df = pd.concat(resampled_dfs, axis=0).sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:31.342997Z","iopub.execute_input":"2025-05-05T21:12:31.343237Z","iopub.status.idle":"2025-05-05T21:12:31.364715Z","shell.execute_reply.started":"2025-05-05T21:12:31.343214Z","shell.execute_reply":"2025-05-05T21:12:31.363467Z"}},"outputs":[],"execution_count":8},{"id":"376ad0c7","cell_type":"code","source":"texts = train_df['text'].to_numpy()\nlabels = train_df['labels'].to_numpy()\nprint(Counter(labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:31.365795Z","iopub.execute_input":"2025-05-05T21:12:31.366122Z","iopub.status.idle":"2025-05-05T21:12:31.375894Z","shell.execute_reply.started":"2025-05-05T21:12:31.366098Z","shell.execute_reply":"2025-05-05T21:12:31.375075Z"}},"outputs":[{"name":"stdout","text":"Counter({5: 1974, 6: 1974, 3: 1974, 1: 1974, 2: 1974, 0: 1974, 4: 1974})\n","output_type":"stream"}],"execution_count":9},{"id":"8d8923bd","cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\n\ndataset = DatasetDict({\n    'train' : train_dataset,\n    'val': val_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:31.376709Z","iopub.execute_input":"2025-05-05T21:12:31.377053Z","iopub.status.idle":"2025-05-05T21:12:31.666913Z","shell.execute_reply.started":"2025-05-05T21:12:31.377025Z","shell.execute_reply":"2025-05-05T21:12:31.666357Z"}},"outputs":[],"execution_count":10},{"id":"13e0d7fd","cell_type":"code","source":"# Токенизация\ntokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:31.670058Z","iopub.execute_input":"2025-05-05T21:12:31.670340Z","iopub.status.idle":"2025-05-05T21:12:55.404743Z","shell.execute_reply.started":"2025-05-05T21:12:31.670323Z","shell.execute_reply":"2025-05-05T21:12:55.404107Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3affff9f46594539aaaadd05cd149f51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46f2c2150dc644bfa439de58b428e3d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec2fbad87a94afda47b27b3a2a80e19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5387be2788274049a8c1a3dc7b8e0f86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3dfed2764434d24a035f38663dcd780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2471 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78452f17048d4bebb8bc91d7c474cb5c"}},"metadata":{}}],"execution_count":11},{"id":"2ae4ae1d","cell_type":"code","source":"tokenized_datasets.set_format('torch')\ntokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:55.405774Z","iopub.execute_input":"2025-05-05T21:12:55.406253Z","iopub.status.idle":"2025-05-05T21:12:55.411854Z","shell.execute_reply.started":"2025-05-05T21:12:55.406230Z","shell.execute_reply":"2025-05-05T21:12:55.411158Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 13818\n    })\n    val: Dataset({\n        features: ['Unnamed: 0', 'text', 'labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2471\n    })\n})"},"metadata":{}}],"execution_count":12},{"id":"ad4027bd","cell_type":"code","source":"# 5. Инициализация модели (остается без изменений)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = BertForSequenceClassification.from_pretrained(\n    'DeepPavlov/rubert-base-cased',\n    num_labels=len(class_mapping)\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:12:55.412649Z","iopub.execute_input":"2025-05-05T21:12:55.412885Z","iopub.status.idle":"2025-05-05T21:13:00.631544Z","shell.execute_reply.started":"2025-05-05T21:12:55.412861Z","shell.execute_reply":"2025-05-05T21:13:00.630657Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3bad9289dc94f3c86713751982110f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7014d3cb7664834abf7ae9946677b50"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"id":"53875223","cell_type":"code","source":"# Создание модели\nmodel = BertForSequenceClassification.from_pretrained(\n    \"DeepPavlov/rubert-base-cased\", \n    num_labels=len(class_mapping)\n    )\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)  # Для multi-class\n    \n    # Для multi-label (раскомментировать):\n    # predictions = (predictions > 0).astype(int)  # Логиты уже через sigmoid\n    \n    return {\n        'f1 macro': f1_score(labels, predictions, average='macro'),\n        'f1 micro': f1_score(labels, predictions, average='micro'),\n        'f1 weighted': f1_score(labels, predictions, average='weighted'),\n        'accuracy': accuracy_score(labels, predictions),\n        'precision': precision_score(labels, predictions, average='macro'),\n        'recall': recall_score(labels, predictions, average='macro'),\n        'Loss': hamming_loss(labels, predictions)\n    }\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=8,\n    num_train_epochs=20,\n    eval_strategy=\"steps\",\n    log_level='info',\n    do_train=True,  # Ключевое изменение!\n    do_eval=True,\n    logging_steps=200,\n    save_steps=1500,\n    eval_steps=200,\n    fp16=True,  # Если GPU поддерживает\n    report_to=[\"tensorboard\"],\n    metric_for_best_model='eval_f1 micro'\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"val\"],\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:13:00.632504Z","iopub.execute_input":"2025-05-05T21:13:00.632742Z","iopub.status.idle":"2025-05-05T21:13:03.140856Z","shell.execute_reply.started":"2025-05-05T21:13:00.632726Z","shell.execute_reply":"2025-05-05T21:13:03.139996Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing auto half precision backend\n","output_type":"stream"}],"execution_count":14},{"id":"5bb8ae22","cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T21:13:03.142161Z","iopub.execute_input":"2025-05-05T21:13:03.142996Z","iopub.status.idle":"2025-05-06T01:59:08.085974Z","shell.execute_reply.started":"2025-05-05T21:13:03.142970Z","shell.execute_reply":"2025-05-06T01:59:08.085369Z"}},"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, Unnamed: 0. If text, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 13,818\n  Num Epochs = 20\n  Instantaneous batch size per device = 16\n  Training with DataParallel so batch size has been adjusted to: 32\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 8,640\n  Number of trainable parameters = 177,858,823\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8640' max='8640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8640/8640 4:46:01, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1 macro</th>\n      <th>F1 micro</th>\n      <th>F1 weighted</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>1.201800</td>\n      <td>0.333064</td>\n      <td>0.651186</td>\n      <td>0.666936</td>\n      <td>0.664151</td>\n      <td>0.666936</td>\n      <td>0.669438</td>\n      <td>0.671612</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.655500</td>\n      <td>0.228248</td>\n      <td>0.761865</td>\n      <td>0.771752</td>\n      <td>0.773492</td>\n      <td>0.771752</td>\n      <td>0.768927</td>\n      <td>0.769651</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.318300</td>\n      <td>0.196277</td>\n      <td>0.796394</td>\n      <td>0.803723</td>\n      <td>0.802657</td>\n      <td>0.803723</td>\n      <td>0.801592</td>\n      <td>0.792316</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.255000</td>\n      <td>0.160259</td>\n      <td>0.831045</td>\n      <td>0.839741</td>\n      <td>0.838620</td>\n      <td>0.839741</td>\n      <td>0.830467</td>\n      <td>0.832642</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.204800</td>\n      <td>0.158236</td>\n      <td>0.830628</td>\n      <td>0.841764</td>\n      <td>0.841947</td>\n      <td>0.841764</td>\n      <td>0.830056</td>\n      <td>0.837137</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.164100</td>\n      <td>0.147309</td>\n      <td>0.844921</td>\n      <td>0.852691</td>\n      <td>0.853849</td>\n      <td>0.852691</td>\n      <td>0.843017</td>\n      <td>0.848384</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.158800</td>\n      <td>0.135573</td>\n      <td>0.853654</td>\n      <td>0.864427</td>\n      <td>0.864085</td>\n      <td>0.864427</td>\n      <td>0.861067</td>\n      <td>0.849957</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.196800</td>\n      <td>0.145285</td>\n      <td>0.844741</td>\n      <td>0.854715</td>\n      <td>0.855162</td>\n      <td>0.854715</td>\n      <td>0.851637</td>\n      <td>0.840777</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.243400</td>\n      <td>0.148523</td>\n      <td>0.842762</td>\n      <td>0.851477</td>\n      <td>0.852381</td>\n      <td>0.851477</td>\n      <td>0.852269</td>\n      <td>0.839069</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.197300</td>\n      <td>0.143262</td>\n      <td>0.845377</td>\n      <td>0.856738</td>\n      <td>0.855882</td>\n      <td>0.856738</td>\n      <td>0.842157</td>\n      <td>0.850552</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.317000</td>\n      <td>0.137596</td>\n      <td>0.850337</td>\n      <td>0.862404</td>\n      <td>0.863367</td>\n      <td>0.862404</td>\n      <td>0.850316</td>\n      <td>0.854076</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.211900</td>\n      <td>0.132740</td>\n      <td>0.856083</td>\n      <td>0.867260</td>\n      <td>0.865975</td>\n      <td>0.867260</td>\n      <td>0.860821</td>\n      <td>0.852602</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.269700</td>\n      <td>0.165925</td>\n      <td>0.822088</td>\n      <td>0.834075</td>\n      <td>0.834131</td>\n      <td>0.834075</td>\n      <td>0.828684</td>\n      <td>0.828374</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.242600</td>\n      <td>0.130716</td>\n      <td>0.859647</td>\n      <td>0.869284</td>\n      <td>0.869461</td>\n      <td>0.869284</td>\n      <td>0.867092</td>\n      <td>0.855616</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.215300</td>\n      <td>0.144476</td>\n      <td>0.844963</td>\n      <td>0.855524</td>\n      <td>0.854958</td>\n      <td>0.855524</td>\n      <td>0.842894</td>\n      <td>0.853668</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.148500</td>\n      <td>0.134359</td>\n      <td>0.858150</td>\n      <td>0.865641</td>\n      <td>0.866144</td>\n      <td>0.865641</td>\n      <td>0.856449</td>\n      <td>0.863103</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.178200</td>\n      <td>0.127883</td>\n      <td>0.861989</td>\n      <td>0.872117</td>\n      <td>0.871980</td>\n      <td>0.872117</td>\n      <td>0.861436</td>\n      <td>0.864834</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.150800</td>\n      <td>0.132740</td>\n      <td>0.856223</td>\n      <td>0.867260</td>\n      <td>0.867994</td>\n      <td>0.867260</td>\n      <td>0.858275</td>\n      <td>0.858867</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.153900</td>\n      <td>0.129098</td>\n      <td>0.861709</td>\n      <td>0.870902</td>\n      <td>0.870292</td>\n      <td>0.870902</td>\n      <td>0.875754</td>\n      <td>0.853198</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.172700</td>\n      <td>0.129098</td>\n      <td>0.860033</td>\n      <td>0.870902</td>\n      <td>0.871435</td>\n      <td>0.870902</td>\n      <td>0.858980</td>\n      <td>0.863505</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.139500</td>\n      <td>0.121408</td>\n      <td>0.870169</td>\n      <td>0.878592</td>\n      <td>0.877994</td>\n      <td>0.878592</td>\n      <td>0.875973</td>\n      <td>0.866299</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.119300</td>\n      <td>0.118575</td>\n      <td>0.871436</td>\n      <td>0.881425</td>\n      <td>0.881328</td>\n      <td>0.881425</td>\n      <td>0.872576</td>\n      <td>0.870977</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.102500</td>\n      <td>0.120599</td>\n      <td>0.871453</td>\n      <td>0.879401</td>\n      <td>0.878886</td>\n      <td>0.879401</td>\n      <td>0.876167</td>\n      <td>0.867307</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.112400</td>\n      <td>0.128288</td>\n      <td>0.857879</td>\n      <td>0.871712</td>\n      <td>0.871797</td>\n      <td>0.871712</td>\n      <td>0.855427</td>\n      <td>0.863996</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.078200</td>\n      <td>0.117361</td>\n      <td>0.873774</td>\n      <td>0.882639</td>\n      <td>0.882500</td>\n      <td>0.882639</td>\n      <td>0.879459</td>\n      <td>0.868690</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>0.116400</td>\n      <td>0.130312</td>\n      <td>0.859400</td>\n      <td>0.869688</td>\n      <td>0.869504</td>\n      <td>0.869688</td>\n      <td>0.860851</td>\n      <td>0.859764</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>0.102700</td>\n      <td>0.127479</td>\n      <td>0.863372</td>\n      <td>0.872521</td>\n      <td>0.872558</td>\n      <td>0.872521</td>\n      <td>0.862128</td>\n      <td>0.865550</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>0.118400</td>\n      <td>0.118171</td>\n      <td>0.872714</td>\n      <td>0.881829</td>\n      <td>0.881578</td>\n      <td>0.881829</td>\n      <td>0.876041</td>\n      <td>0.870064</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>0.096200</td>\n      <td>0.115743</td>\n      <td>0.873495</td>\n      <td>0.884257</td>\n      <td>0.883695</td>\n      <td>0.884257</td>\n      <td>0.871894</td>\n      <td>0.875754</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.096700</td>\n      <td>0.126265</td>\n      <td>0.863041</td>\n      <td>0.873735</td>\n      <td>0.873815</td>\n      <td>0.873735</td>\n      <td>0.862943</td>\n      <td>0.865438</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>0.082300</td>\n      <td>0.125860</td>\n      <td>0.867035</td>\n      <td>0.874140</td>\n      <td>0.875022</td>\n      <td>0.874140</td>\n      <td>0.871591</td>\n      <td>0.865167</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>0.091000</td>\n      <td>0.123027</td>\n      <td>0.866684</td>\n      <td>0.876973</td>\n      <td>0.876588</td>\n      <td>0.876973</td>\n      <td>0.869409</td>\n      <td>0.865571</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>0.098600</td>\n      <td>0.120194</td>\n      <td>0.870496</td>\n      <td>0.879806</td>\n      <td>0.879538</td>\n      <td>0.879806</td>\n      <td>0.873019</td>\n      <td>0.869454</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>0.074900</td>\n      <td>0.122622</td>\n      <td>0.867196</td>\n      <td>0.877378</td>\n      <td>0.877028</td>\n      <td>0.877378</td>\n      <td>0.869872</td>\n      <td>0.867029</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.077200</td>\n      <td>0.116552</td>\n      <td>0.875534</td>\n      <td>0.883448</td>\n      <td>0.883006</td>\n      <td>0.883448</td>\n      <td>0.880868</td>\n      <td>0.871339</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>0.095200</td>\n      <td>0.118575</td>\n      <td>0.873415</td>\n      <td>0.881425</td>\n      <td>0.880813</td>\n      <td>0.881425</td>\n      <td>0.876292</td>\n      <td>0.872142</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>0.071700</td>\n      <td>0.122218</td>\n      <td>0.867864</td>\n      <td>0.877782</td>\n      <td>0.877845</td>\n      <td>0.877782</td>\n      <td>0.866523</td>\n      <td>0.871175</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>0.083600</td>\n      <td>0.119790</td>\n      <td>0.870554</td>\n      <td>0.880210</td>\n      <td>0.879470</td>\n      <td>0.880210</td>\n      <td>0.871871</td>\n      <td>0.870495</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>0.081800</td>\n      <td>0.118980</td>\n      <td>0.873247</td>\n      <td>0.881020</td>\n      <td>0.880621</td>\n      <td>0.881020</td>\n      <td>0.878044</td>\n      <td>0.869752</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.080900</td>\n      <td>0.123027</td>\n      <td>0.868379</td>\n      <td>0.876973</td>\n      <td>0.876613</td>\n      <td>0.876973</td>\n      <td>0.871770</td>\n      <td>0.867018</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>0.076200</td>\n      <td>0.118171</td>\n      <td>0.873020</td>\n      <td>0.881829</td>\n      <td>0.881575</td>\n      <td>0.881829</td>\n      <td>0.877353</td>\n      <td>0.869856</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>0.072300</td>\n      <td>0.119385</td>\n      <td>0.871874</td>\n      <td>0.880615</td>\n      <td>0.880299</td>\n      <td>0.880615</td>\n      <td>0.877176</td>\n      <td>0.867757</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>0.067300</td>\n      <td>0.119385</td>\n      <td>0.871478</td>\n      <td>0.880615</td>\n      <td>0.880232</td>\n      <td>0.880615</td>\n      <td>0.876335</td>\n      <td>0.867834</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to /kaggle/working/results/checkpoint-1500\nConfiguration saved in /kaggle/working/results/checkpoint-1500/config.json\nModel weights saved in /kaggle/working/results/checkpoint-1500/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\nSaving model checkpoint to /kaggle/working/results/checkpoint-3000\nConfiguration saved in /kaggle/working/results/checkpoint-3000/config.json\nModel weights saved in /kaggle/working/results/checkpoint-3000/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to /kaggle/working/results/checkpoint-4500\nConfiguration saved in /kaggle/working/results/checkpoint-4500/config.json\nModel weights saved in /kaggle/working/results/checkpoint-4500/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\nSaving model checkpoint to /kaggle/working/results/checkpoint-6000\nConfiguration saved in /kaggle/working/results/checkpoint-6000/config.json\nModel weights saved in /kaggle/working/results/checkpoint-6000/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to /kaggle/working/results/checkpoint-7500\nConfiguration saved in /kaggle/working/results/checkpoint-7500/config.json\nModel weights saved in /kaggle/working/results/checkpoint-7500/model.safetensors\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to /kaggle/working/results/checkpoint-8640\nConfiguration saved in /kaggle/working/results/checkpoint-8640/config.json\nModel weights saved in /kaggle/working/results/checkpoint-8640/model.safetensors\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=8640, training_loss=0.18070496384192397, metrics={'train_runtime': 17164.4423, 'train_samples_per_second': 16.101, 'train_steps_per_second': 0.503, 'total_flos': 7.2716635579392e+16, 'train_loss': 0.18070496384192397, 'epoch': 20.0})"},"metadata":{}}],"execution_count":15},{"id":"fa23707b","cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/my_bert_one_aug_classifier\")\ntokenizer.save_pretrained(\"/kaggle/working/my_bert_one_aug_classifier\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:59:08.086735Z","iopub.execute_input":"2025-05-06T01:59:08.087056Z","iopub.status.idle":"2025-05-06T01:59:09.834534Z","shell.execute_reply.started":"2025-05-06T01:59:08.087039Z","shell.execute_reply":"2025-05-06T01:59:09.833792Z"}},"outputs":[{"name":"stderr","text":"Configuration saved in /kaggle/working/my_bert_one_aug_classifier/config.json\nModel weights saved in /kaggle/working/my_bert_one_aug_classifier/model.safetensors\ntokenizer config file saved in /kaggle/working/my_bert_one_aug_classifier/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/my_bert_one_aug_classifier/special_tokens_map.json\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/my_bert_one_aug_classifier/tokenizer_config.json',\n '/kaggle/working/my_bert_one_aug_classifier/special_tokens_map.json',\n '/kaggle/working/my_bert_one_aug_classifier/vocab.txt',\n '/kaggle/working/my_bert_one_aug_classifier/added_tokens.json')"},"metadata":{}}],"execution_count":16},{"id":"5f60dc95","cell_type":"code","source":"print(trainer.evaluate()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:59:09.835352Z","iopub.execute_input":"2025-05-06T01:59:09.835630Z","iopub.status.idle":"2025-05-06T01:59:59.560270Z","shell.execute_reply.started":"2025-05-06T01:59:09.835609Z","shell.execute_reply":"2025-05-06T01:59:59.559687Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, Unnamed: 0. If text, __index_level_0__, Unnamed: 0 are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 2471\n  Batch size = 16\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='155' max='155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [155/155 00:49]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 1.9790066480636597, 'eval_f1 macro': 0.8715654241835138, 'eval_f1 micro': 0.8806151355726427, 'eval_f1 weighted': 0.880219668741596, 'eval_accuracy': 0.8806151355726427, 'eval_precision': 0.8764716077764769, 'eval_recall': 0.8678341776923343, 'eval_Loss': 0.11938486442735735, 'eval_runtime': 49.7073, 'eval_samples_per_second': 49.711, 'eval_steps_per_second': 3.118, 'epoch': 20.0}\n","output_type":"stream"}],"execution_count":17},{"id":"58bff270","cell_type":"code","source":"new_texts = [\"Анкара Месси забил гол в ворота франции\", \"ай Литвин красава ай чисто на кондциях залетел ай да лев\", \"Америка расширила список санкция против России\", \"купите макбук за 140к и получите наушники в подарок\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:59:59.560979Z","iopub.execute_input":"2025-05-06T01:59:59.561198Z","iopub.status.idle":"2025-05-06T01:59:59.565307Z","shell.execute_reply.started":"2025-05-06T01:59:59.561182Z","shell.execute_reply":"2025-05-06T01:59:59.564673Z"}},"outputs":[],"execution_count":18},{"id":"3aa8b3e2","cell_type":"code","source":"def predict(text):\n    # Токенизация текста\n    inputs = tokenizer(\n        text,\n        padding=True,\n        truncation=True,\n        max_length=512,\n        return_tensors=\"pt\"\n    ).to(device)\n    \n    # Предсказание\n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    # Получение метки класса\n    probs = torch.sigmoid(outputs.logits)\n    pred_class = torch.argmax(probs).item()\n    \n    id2label = {\n        0: 'другое',\n        1: \"личная жизнь\",\n        2: \"политика\", \n        3: \"реклама\",\n        4: \"соцсети\",\n        5: \"спорт\",\n        6: \"юмор\"\n    }\n\n    for class_id, prob in enumerate(probs.cpu().numpy()[0]):\n        print(f\"{id2label[class_id]}: {prob:.4f}\")  # 4 знака после запятой","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T05:06:23.200580Z","iopub.execute_input":"2025-05-06T05:06:23.200788Z","iopub.status.idle":"2025-05-06T05:06:23.209292Z","shell.execute_reply.started":"2025-05-06T05:06:23.200763Z","shell.execute_reply":"2025-05-06T05:06:23.208304Z"}},"outputs":[],"execution_count":1},{"id":"e1d0df85","cell_type":"code","source":"class_mapping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T05:06:33.933972Z","iopub.execute_input":"2025-05-06T05:06:33.934523Z","iopub.status.idle":"2025-05-06T05:06:33.995700Z","shell.execute_reply.started":"2025-05-06T05:06:33.934503Z","shell.execute_reply":"2025-05-06T05:06:33.994761Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3827628784.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'class_mapping' is not defined"],"ename":"NameError","evalue":"name 'class_mapping' is not defined","output_type":"error"}],"execution_count":2},{"id":"778e9d12","cell_type":"code","source":"predict('Спортивная энергия в каждом глотке — заряжайся и побеждай с новым напитком для чемпионов!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T05:06:43.645721Z","iopub.execute_input":"2025-05-06T05:06:43.645982Z","iopub.status.idle":"2025-05-06T05:06:43.655221Z","shell.execute_reply.started":"2025-05-06T05:06:43.645961Z","shell.execute_reply":"2025-05-06T05:06:43.654289Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1452413141.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Спортивная энергия в каждом глотке — заряжайся и побеждай с новым напитком для чемпионов!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/40140326.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Токенизация текста\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     inputs = tokenizer(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"],"ename":"NameError","evalue":"name 'tokenizer' is not defined","output_type":"error"}],"execution_count":3},{"id":"4d785251","cell_type":"code","source":"predict('Достигай рекордов с кроссовками, которые выбирают профи!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:59:59.950485Z","iopub.status.idle":"2025-05-06T01:59:59.950809Z","shell.execute_reply.started":"2025-05-06T01:59:59.950646Z","shell.execute_reply":"2025-05-06T01:59:59.950661Z"}},"outputs":[],"execution_count":null},{"id":"87928a00","cell_type":"code","source":"predict('Подпитывай чемпионский дух — белковый батончик для твоих тренировок!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T01:59:59.951860Z","iopub.status.idle":"2025-05-06T01:59:59.952062Z","shell.execute_reply.started":"2025-05-06T01:59:59.951967Z","shell.execute_reply":"2025-05-06T01:59:59.951975Z"}},"outputs":[],"execution_count":null}]}